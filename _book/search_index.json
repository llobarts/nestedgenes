[["index.html", "Nested genes code Chapter 1 About 1.1 Abstract 1.2 Abstract", " Nested genes code Esmeralda G. Legarda 2023-11-08 Chapter 1 About This is a code collection that contains the main steps for parsing, processing and visualizing data of the study of the nested genes p19 and p22. Each chapter is a part of the methodology of the study of the overlap of two genes. R, Python and Bash are the languages used for this purpose. Imagen del art√≠culo 1.1 Abstract Viruses with small genomes may encode overlapping or nested open reading frames that increase their coding capacity. The extent by which the constraints upon spatial structures of the two encoded proteins limit the evolvability of nested genes have not been deeply studied. Here, we examined the evolution of the tombusvirus proteins p22 and p19, encoded by nested genes. The structure of p19, the RNA silencing suppressor of the Tombusviridae family, has been determined experimentally; it belongs to the RAGNYA fold from the alpha + beta class. The structure of p22, the cell-to-cell movement protein (MP) from the 30K family common to many families of plant viruses, is not known. AlphaFold structure predictions suggest that the conserved structural core of p22, and of other 30K MPs, has a single jelly-roll fold from the all-beta class, structurally similar to capsid proteins from plant and animal viruses. The sequence and structure conservation within each of the p19 and p22 families coexists with asymmetric selection, mostly negative for p22 but positive for p19. The nucleotide sequence in the alternative reading frames imposes subtle limitations on the types of secondary structures that can be encoded. These limitations arise from specific preferences in the alternative frame due to the interplay of amino acid composition and selection pressures. Thus, the properties of the genetic code and of the encoded amino acid sequences permit the development of compact, well-ordered folds from different structural classes by two similarly-sized nested proteins. An ancient origin of p22 from icosahedral virus capsid protein is likely, whereas p19 may have emerged by stepwise increase in the length of the overprinted gene, acquisition of secondary structure elements by the protein product, and its convergent evolution towards the RAGNYA fold. 1.2 Abstract Some additional files can be found in GitHub. "],["blast-and-e-utilities.html", "Chapter 2 Blast and E-utilities 2.1 PSI-BLAST 2.2 Protein ID to nucleotides 2.3 Species to family", " Chapter 2 Blast and E-utilities 2.1 PSI-BLAST This section shows a bash file that quickly allows to run PSI-BLAST with a simple line for different inputs (saved in the same directory). #!/bin/bash # This program generates results of running PSI-BLAST # Reading FLAGS while getopts :p:e:i:d:D:t: flag do case ${flag} in p) psiblast=${OPTARG};; e) evalue=${OPTARG};; i) iter=${OPTARG};; d) dbname=${OPTARG};; D) dbpath=${OPTARG};; t) threads=${OPTARG};; esac done # Initial settings format=&#39;7 qaccver saccver pident length mismatch gapopen qstart qend sstart send stitle ssciname sskingdom&#39; currpath=$(pwd) evalue_float=$(expr $evalue) num_itera=$(expr $iter) # Create directory OUTPUT_DIR=${currpath}/Results/temp/psiblast_${evalue}_${iter} cd $dbpath for INPUT in $(ls ${currpath}/Results/temp/Fastafiles) do # Run PSI-BLAST OUTPUT=${OUTPUT_DIR}/${INPUT%.*}_${evalue}_${iter} code=$($psiblast -query ${currpath}/Results/temp/Fastafiles/$INPUT -db $dbname -evalue $evalue_float -num_iterations $num_itera -outfmt &quot;$format&quot; -out $OUTPUT.blast -out_pssm $OUTPUT.matrix.smp -seg yes -save_pssm_after_last_round -num_threads $threads) eval $code done From the terminal, run this code: /bin/sh Models/dopsiblast.sh -p path_psiblast -e e_value -i max_iter -d db_name -D db_path -t num_threads 2.2 Protein ID to nucleotides Here is a command that is very useful when we want to change to nucleotides analysis. The output consists of three columns: accession number of protein, of nucleotide and the nucleotidic sequence. elink -db protein -id CAG38136.1 -target nuccore | efetch -format gbc | xtract -insd protein_id CDS sub_sequence It is also possible to get the information in a GFF-like format of an accession of nucleotides. esearch -db nuccore -query OP477335.1 | efetch -format ft Or with the format of genebank. esearch -db nuccore -query OP477335.1 | efetch -format gb 2.3 Species to family With the following code we can generate a list of unique families (or other rank) if we gave a file containing species as input. This file must have one species per line. import subprocess import pandas as pd import matplotlib.pyplot as plt # Read list of species from file with open(&#39;virus_species.txt&#39;, &#39;r&#39;) as f: virus_list = [line.strip() for line in f] # Initialize empty dictionary to store family frequencies family_counts = {} # Loop through virus list and retrieve lineage information for virus in virus_list: command = f&#39;esearch -db taxonomy -query &quot;{virus}[Organism]&quot; | efetch -format docsum | xtract -pattern DocumentSummary -element Lineage&#39; output = subprocess.check_output(command, shell=True) lineage = output.decode().strip() # Extract family name from lineage and increment frequency count if len(lineage) != 0: family = lineage.split(&quot;;&quot;)[2].strip() family_counts[family] = family_counts.get(family, 0) + 1 print(len(family_counts.keys())) print(len(family_counts.keys())) # Convert family counts to Pandas DataFrame and plot as bar chart df = pd.DataFrame.from_dict(family_counts, orient=&#39;index&#39;, columns=[&#39;Frequency&#39;]) ax = df.plot(kind=&#39;bar&#39;, rot=0, legend=None) ax.set_xlabel(&#39;Virus Family&#39;) ax.set_ylabel(&#39;Frequency&#39;) plt.show() "],["distances-with-clustering-in-clans.html", "Chapter 3 Distances with clustering in CLANS 3.1 Read CLANS file 3.2 Create a DataFrame 3.3 Calculate centroids and distances 3.4 Run", " Chapter 3 Distances with clustering in CLANS In this chapter we proceed to parse the output of the clustering carried out with CLANS (CLuster ANalysis of Sequences) software. It performs an all-against-all comparison of the sequences and it calculates the p-values for the HSPs (High-Scoring Segment Pairs1) found between these sequences. As output we get a file .clans structured with the following sections: Parameters Coordinates of the last visualization in 3D with CLANS software Sequences Groups of sequences after clustering Positions for each sequence in a 3D space. HSP values Our aim here is to generate a matrix of distances between the groups of proteins clustered with CLANS for their hierarchical clustering, using Euclidean distances. 3.1 Read CLANS file import os import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from scipy.cluster.hierarchy import linkage from scipy.spatial.distance import squareform from scipy.cluster import hierarchy There are two functions in charge of information reading. The first one, read_clans_file, gathers 3 chunks of information at level of sequence, group and position per sequence, using the second function get_info_chunk. def read_clans_file(filename): listobjects = [[],[],[]] wordinit_list = [&quot;&lt;seq&gt;&quot;, &quot;&lt;seqgroups&gt;&quot;, &quot;&lt;pos&gt;&quot;] wordend_list = [&quot;&lt;/seq&gt;&quot;, &quot;&lt;/seqgroups&gt;&quot;, &quot;&lt;/pos&gt;&quot;] with open(filename, &#39;r&#39;) as fileopen: for i in range(len(wordinit_list)): get_info_chunk(wordinit_list[i], wordend_list[i], listobjects[i], fileopen) return listobjects def get_info_chunk(wordinit, wordend, listobjects, fileopen): end = True line = fileopen.readline().strip() while not line.startswith(wordend): if line.startswith(wordinit): end = False elif not end: listobjects.append(line.strip().split(&quot; &quot;)) line = fileopen.readline().strip() We read the names of the groups, previously assigned with the CLANS software. def getgroups(groups): sep_groups = [] for i in groups: for l in i: if l.startswith(&quot;numbers&quot;): sep_groups.append(l.replace(&quot;numbers=&quot;, &quot;&quot;).split(&quot;;&quot;)[:-1]) return sep_groups def assign_groups(groups, size): last_group = len(groups) numbers_group = [last_group] * size cont = 0 for group in range(len(groups)): for i in range(len(groups[group])): numbers_group[int(groups[group][i])] = cont cont += 1 return numbers_group def assingnamegroup(groups, numbers_group): names_group = [] names = [] for i in groups: for l in i: if l.startswith(&quot;name&quot;) and l.find(&quot;_&quot;) &gt; 0: names.append(l.replace(&quot;name=&quot;, &quot;&quot;).replace(&quot;_&quot;, &quot;, &quot;)) elif l.startswith(&quot;name&quot;): names.append(l.replace(&quot;name=&quot;, &quot;&quot;)) cont = 0 for i in numbers_group: if i &lt; len(names): names_group.append(names[i]) else: names_group.append(&quot;NaN&quot;) return names, names_group 3.2 Create a DataFrame We create a DataFrame that contains all the sequences with information about its position and group. def joininfo(info, coord, groups_names): info_df = pd.Series([ x for x in info if info.index(x) % 2 == 0 ]) info_df_aux = pd.Series([ x for x in info if info.index(x) % 2 != 0 ]) coords_df = pd.DataFrame(coord, columns = [&quot;number&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;]) del coords_df[&quot;number&quot;] group_df = pd.DataFrame(groups_names, columns = [&quot;group&quot;]) info_df = pd.concat([info_df, info_df_aux, coords_df, group_df], axis=1) return info_df 3.3 Calculate centroids and distances The Euclidean distance will be used as a measure of similarity between two groups. The objective of the function calculate_centroids is to calculate the centroids of each group. Then, the function calculate_distances returns a DataFrame with pairwise distances. def calculate_centroids(info_df, names): centroids = {} for element in range(len(names)): info_df_group = info_df[info_df[&quot;group&quot;] == names[element]] centroids[element] = [np.mean([float(i) for i in list(info_df_group[&quot;x&quot;])]), np.mean([float(i) for i in list(info_df_group[&quot;y&quot;])]), np.mean([float(i) for i in list(info_df_group[&quot;z&quot;])])] return centroids def calculate_distances(centroids, names): matrix_distances = np.zeros(shape=(len(centroids),len(centroids))) for centroid_A in centroids.keys(): for centroid_B in centroids.keys(): matrix_distances[centroid_A][centroid_B] = \\ np.sqrt((centroids[centroid_B][0] - centroids[centroid_A][0])**2 + \\ (centroids[centroid_B][1] - centroids[centroid_A][1])**2 + \\ (centroids[centroid_B][2] - centroids[centroid_A][2])**2) return pd.DataFrame(matrix_distances, columns = names, index = names) 3.3.1 Plot the clustermap This function plots the distances with a hierarchical clustering that can be done with different methods. A metric to asses their ability for recreating the pairwise distances is the cophenetic correlation coefficient (the higher, the better it explains the pairwise relationships). Some instances of methods are simple, average, complete or centroid. def plot_clans_distances(data, method): cmap = sns.color_palette(&quot;YlGn&quot;, as_cmap=True) cmap = cmap.reversed() # Compute the hierarchical clustering data_square = squareform(data) linkage = hierarchy.linkage(data_square, method=method) # Plot the heatmap with clustered rows and columns sns.clustermap(data, figsize=(8,8), method=method, row_linkage=linkage, col_linkage=linkage, cmap=cmap, vmin=0, vmax=90, cbar_pos=(0.02, 0.8225, 0.02, 0.18)) c, coph_dists = hierarchy.cophenet(linkage, data_square) # Print, save pdf and show print(&quot;Cophenetic correlation coefficient:&quot;, c) plt.savefig(&quot;/Users/esmeralda/Documents/TFM/3_testprograms/familes_core_AF2/analyse/heatmap.pdf&quot;, format=&quot;pdf&quot;, bbox_inches=&quot;tight&quot;) plt.show() 3.4 Run # Read info name = &quot;4406328_3D_comparison.clans&quot; info, groups, coord = read_clans_file(name) # Process assigned groups and their names sep_groups = getgroups(groups) numbers_group = assigngroups(sep_groups, len(coord)) names, groups_names = assingnamegroup(groups, numbers_group) # Joined into a DataFrame info_df = joininfo(info, coord, groups_names) # Calculations for Euclidean distances in 3D centroids = calculate_centroids(info_df, names) matrix_distances = calculate_distances(centroids, names) # Plot clustermap plot_clans_distances(matrix_distances, method) High-Scoring Segment Pairs: regions of local similarity found during sequence comparison with BLAST (Basic Local Alignment Search Tool)‚Ü©Ô∏é "],["distances-with-chimerax.html", "Chapter 4 Distances with ChimeraX 4.1 Obtaining RMSD with ChimeraX 4.2 Hiarachical clustering", " Chapter 4 Distances with ChimeraX UCSF ChimeraX-1.6.1 has some routines implemented in Python 3.9 of which we can benefit. The purpose of this chapter is obtaining a matrix of RMSD (root-mean-square deviation) distances using a tool of ChimeraX named MatchMaker. This matrix will be used for hierarchical clustering. 4.1 Obtaining RMSD with ChimeraX As we had a list of 29 PDB files, here is the automated pairwise comparison implemented. The following code of this first section has to be gathered and saved in a Python file (.py) and opened by the ChimeraX software open option. 4.1.1 Import libraries and data We use the package chimerax, previously installed with pip command. For the pairwise comparison, all the structures in PDB format were saved in the same directory. import os from chimerax.core.commands import run # Directory containing the PDB files pdb_dir = &#39;/Users/esmeralda/Documents/TFM/article/structures&#39; # List all PDB files in the directory pdb_files = [f for f in os.listdir(pdb_dir) if f.endswith(&#39;.pdb&#39;)] # Load PDB structures structures = [] for pdb_file in pdb_files: file_path = os.path.join(pdb_dir, pdb_file) structure = run(session, &quot;open &quot; + file_path) structures.append(structure[0]) # Append the first (and only) structure from the result list 4.1.2 MatchMaker This step includes the setting of some parameters such as the type of alignment or the weight of secondary structure in the alignment. The names of the structures were formatted according to the type of nomenclature of the PDB files chosen previously. Notice that the function run allows the user to write any Chimera command. session refers to the current session. We choose to save full RMSD values. # Parameters for MatchMaker alignment alignment_type = &#39;Needleman-Wunsch&#39; # Type of alignment: &#39;default&#39;, &#39;sequence&#39;, &#39;secondary_structure&#39; ss_weight = 0.7 # Weight of secondary structure in alignment (0.0 to 1.0) rmsd_values = [] # Calculate RMSD all-against-all for i, structure1 in enumerate(structures): for j, structure2 in enumerate(structures[i+1:]): rmsd_result = run(session, f&quot;matchmaker #{structure2.id_string} to #{structure1.id_string} alg {alignment_type} ssFraction {ss_weight}&quot;) rmsd_value = rmsd_result[0] print(rmsd_value.keys()) name1 = structure1.name.split(&#39;_&#39;)[0] name2 = structure2.name.split(&#39;_&#39;)[0] rmsd_values.append([name1, name2, rmsd_value[&quot;full RMSD&quot;]]) 4.1.3 Save csv file Pairwise RMSD values are saved in a CSV file, a comparison per line. # Save RMSD values to CSV file csv_file = &#39;/Users/esmeralda/Documents/TFM/Chimera_compare/rmsd_values.csv&#39; with open(csv_file, &#39;w&#39;) as file: file.write(&#39;Structure 1,Structure 2,RMSD\\n&#39;) for row in rmsd_values: file.write(&#39;,&#39;.join(str(value) for value in row) + &#39;\\n&#39;) Don‚Äôt forget to close the files! We have already finished the acquisition of data in ChimeraX software. # Close the structures for structure in structures: run(session, f&#39;close #{structure.id_string}&#39;) 4.2 Hiarachical clustering Now that we have the RMSD values in a csv file, we move on to construct the matrix of distances in our favorite code editor with the following code. 4.2.1 Libraries and read csv import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt from scipy.cluster.hierarchy import linkage from scipy.spatial.distance import squareform from scipy.cluster import hierarchy # Read node pairs and distances from CSV file df = pd.read_csv(&#39;/Users/esmeralda/Documents/TFM/Chimera_compare/rmsd_values.csv&#39;, sep=&quot;,&quot;) 4.2.2 Create matrix We create a matrix as a DataFrame of pandas package. # Extract unique node labels nodes = sorted(set(df[&#39;Structure 1&#39;]).union(df[&#39;Structure 2&#39;])) # Create a dictionary to map node labels to matrix indices node_indices = {node: index for index, node in enumerate(nodes)} # Initialize the distance matrix as a DataFrame matrix = pd.DataFrame(index=nodes, columns=nodes) matrix = matrix.fillna(0.0) # Assign distances to matrix based on node pairs for _, row in df.iterrows(): node1 = row[&#39;Structure 1&#39;] node2 = row[&#39;Structure 2&#39;] distance = row[&#39;RMSD&#39;] matrix.loc[node1, node2] = distance matrix.loc[node2, node1] = distance 4.2.3 Plot the clustermap This function plots the distances with a hierarchical clustering that can be done with different methods. A metric to asses their ability for recreating the pairwise distances is the cophenetic correlation coefficient (the higher, the better it explains the pairwise relationships). def plot_rmsd_distances(data, method): # Compute the hierarchical clustering data_square = squareform(data) linkage = hierarchy.linkage(data_square, method=method, optimal_ordering=True) # Plot the heatmap with clustered rows and columns sns.clustermap(data, method=method, figsize=(8,8), row_linkage=linkage, col_linkage=linkage, cmap=&quot;viridis&quot;, vmin=0, vmax=25, cbar_pos=(0.02, 0.8225, 0.02, 0.18) ) # Calculate cophenetic correlation coefficient c, coph_dists = hierarchy.cophenet(linkage, data_square) # Print the cophenetic correlation coefficient print(&quot;Cophenetic correlation coefficient:&quot;, c) # Save in pdf format and show plt.savefig(&quot;heatmap_structure.pdf&quot;, format=&quot;pdf&quot;, bbox_inches=&quot;tight&quot;) plt.show() We run the previous function to get the plot displayed and the cophenetic correlation coefficient printed. Some instances of methods are simple, average, complete or centroid. method = &quot;centroid&quot; plot_rmsd_distances(matrix, method) IMAGE PLOT "],["compositional-analyses-of-biological-sequences.html", "Chapter 5 Compositional analyses of biological sequences 5.1 Amino acids 5.2 Nucleotides 5.3 Dinuclotides 5.4 Codons", " Chapter 5 Compositional analyses of biological sequences Compositional data might be useful to be compared between two or more groups and could reveal some overrepresented characteristics. We hereby show some code for the comparison between movement proteins, and also their corresponding encoding genes, with and without overlapping frames. from Bio import SeqIO import pandas as pd import matplotlib.pyplot as plt import numpy as np import scipy.stats import seaborn as sns from statannotations.Annotator import Annotator We define the table of codons and amino acids as well as a classification of amino acids based on their physicochemical properties. Notice that the table of codons is ordered by the degeneracy of the genetic code. table_DNA_to_codon = {&quot;M&quot;: [&quot;ATG&quot;], &quot;W&quot;: [&quot;TGG&quot;], &quot;C&quot;: [&quot;TGT&quot;, &quot;TGC&quot;], &quot;D&quot;: [&quot;GAT&quot;, &quot;GAC&quot;], &quot;E&quot;: [&quot;GAA&quot;, &quot;GAG&quot;], &quot;F&quot;: [&quot;TTT&quot;, &quot;TTC&quot;], &quot;H&quot;: [&quot;CAT&quot;, &quot;CAC&quot;], &quot;K&quot;: [&quot;AAA&quot;, &quot;AAG&quot;], &quot;N&quot;: [&quot;AAT&quot;, &quot;AAC&quot;], &quot;Q&quot;: [&quot;CAA&quot;, &quot;CAG&quot;], &quot;Y&quot;: [&quot;TAT&quot;, &quot;TAC&quot;], &quot;I&quot;: [&quot;ATT&quot;, &quot;ATC&quot;, &quot;ATA&quot;], &quot;A&quot;: [&quot;GCT&quot;, &quot;GCC&quot;, &quot;GCA&quot;, &quot;GCG&quot;], &quot;G&quot;: [&quot;GGT&quot;, &quot;GGC&quot;, &quot;GGA&quot;, &quot;GGG&quot;], &quot;P&quot;: [&quot;CCT&quot;, &quot;CCC&quot;, &quot;CCA&quot;, &quot;CCG&quot;], &quot;T&quot;: [&quot;ACT&quot;, &quot;ACC&quot;, &quot;ACA&quot;, &quot;ACG&quot;], &quot;V&quot;: [&quot;GTT&quot;, &quot;GTC&quot;, &quot;GTA&quot;, &quot;GTG&quot;], &quot;L&quot;: [&quot;CTT&quot;, &quot;CTC&quot;, &quot;CTA&quot;, &quot;CTG&quot;, &quot;TTA&quot;, &quot;TTG&quot;], &quot;R&quot;: [&quot;CGT&quot;, &quot;CGC&quot;, &quot;CGA&quot;, &quot;CGG&quot;, &quot;AGA&quot;, &quot;AGG&quot;], &quot;S&quot;: [&quot;TCT&quot;, &quot;TCC&quot;, &quot;TCA&quot;, &quot;TCG&quot;, &quot;AGT&quot;, &quot;AGC&quot;], &quot;STOP&quot;: [&quot;TAA&quot;, &quot;TGA&quot;, &quot;TAG&quot;] } features_aa = {&quot;nonpolarbig&quot;: [&quot;F&quot;, &quot;W&quot;, &quot;L&quot;, &quot;I&quot;, &quot;M&quot;], &quot;nonpolar&quot;: [&quot;V&quot;, &quot;P&quot;, &quot;A&quot;, &quot;G&quot;], &quot;polar&quot;: [&quot;S&quot;, &quot;C&quot;, &quot;N&quot;, &quot;Q&quot;, &quot;T&quot;, &quot;Y&quot;], &quot;basic&quot;: [&quot;K&quot;, &quot;R&quot;, &quot;H&quot;], &quot;acidic&quot;: [&quot;D&quot;, &quot;E&quot;]} # Bind the codon correspondence of amino acids and amino acid features codons_byfeatures = {} for feat in features_aa: codons_byfeatures[feat] = [] for aminoacid in features_aa[feat]: for codon in table_DNA_to_codon[aminoacid]: codons_byfeatures[feat].append(codon) # Add STOP codons codons_byfeatures[&quot;STOP&quot;] = table_DNA_to_codon[&quot;STOP&quot;] 5.1 Amino acids We counted the number of amino acids within each group of sequences, including the 20 essential amino acids. def getAA(seq, letter): return(round((sum([1.0 for nucl in seq if nucl in [letter]]) / (len(seq)-seq.count(&quot;-&quot;))), ndigits=2)) paths = [&quot;p19_aligned.fa&quot;, &quot;p22_aligned.fa&quot;, &quot;p22 core_aligned.fa&quot;, &quot;other cores_allMP.fa&quot;, &quot;RdRp_aligned.fa&quot;, &quot;CP_aligned.fa&quot;] letters = [&quot;M&quot;, &quot;W&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;H&quot;, &quot;K&quot;, &quot;N&quot;, &quot;Q&quot;, &quot;Y&quot;, &quot;I&quot;, &quot;A&quot;, &quot;G&quot;, &quot;P&quot;, &quot;T&quot;, &quot;V&quot;, &quot;L&quot;, &quot;R&quot;, &quot;S&quot;] df_aa = [] aa_means = [] aa_medians = [] aa_std = [] for i, aminoacid in enumerate(letters): AA_content = [] for alignment in paths: name = alignment[0:alignment.find(&quot;_&quot;)] for record in SeqIO.parse(alignment, &quot;fasta&quot;): count = getAA(str(record.seq), aminoacid) AA_content.append([count, name]) name = aminoacid df_aa.append(pd.DataFrame(AA_content, columns=[name, &quot;Sequence&quot;])) aa_means.append(df_aa[i].groupby(&quot;Sequence&quot;).mean()) aa_medians.append(df_aa[i].groupby(&quot;Sequence&quot;).median()) aa_std.append(df_aa[i].groupby(&quot;Sequence&quot;).std()) In this case, we decided to plot and compare the medians of the amino acid proportions ( of total of amino acids in the sequence). hm_medians = pd.concat(aa_medians, axis = 1) hm_medians = hm_medians.reindex(index = [&#39;RdRp&#39;,&#39;CP&#39;,&#39;p19&#39;, &#39;p22&#39;, &#39;p22 core&#39;, &#39;other cores&#39;]) fig, ax = plt.subplots() plt.rcParams[&quot;figure.figsize&quot;] = [12,1.5] sns.heatmap(hm_medians, ax=ax, cmap=&quot;viridis&quot;) plt.xlabel(&quot;Amino acid&quot;) plt.tight_layout() 5.2 Nucleotides The first approach we tried was counting the proportion of nucleotides in different genes and also within the overlapping region of p19 and p22 genes. def getNT(seq, letter): return(round((sum([1.0 for nucl in seq if nucl in [letter]]) / (len(seq)- seq.count(&quot;-&quot;))), ndigits=2)) paths = [&quot;RdRp_nt_aligned.fa&quot;, &quot;CP_nt_aligned.fa&quot;, &quot;p19_nt_aligned.fa&quot;, &quot;p22_nt_aligned.fa&quot;, &quot;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/concatenate/p22 core_nt_alignment.fa&quot;, &quot;other cores_nt.fa&quot;] letters = [&quot;A&quot;, &quot;T&quot;, &quot;C&quot;, &quot;G&quot;] df_nt = [] nt_only_means = [] nt_only_medians = [] nt_only_std = [] for i, nucleot in enumerate(letters): NT_content = [] for alignment in paths: name = alignment[0:alignment.find(&quot;_&quot;)] if len(name) &gt; 50: name = &quot;p22 core&quot; for record in SeqIO.parse(alignment, &quot;fasta&quot;): count = getNT(str(record.seq), nucleot) NT_content.append([count, name]) if nucleot == &quot;T&quot;: nucleot = &quot;U&quot; name = nucleot df_nt.append(pd.DataFrame(NT_content, columns=[name, &quot;Sequence&quot;])) nt_only_means.append(df_nt[i].groupby(&quot;Sequence&quot;).mean()) nt_only_medians.append(df_nt[i].groupby(&quot;Sequence&quot;).median()) nt_only_std.append(df_nt[i].groupby(&quot;Sequence&quot;).std()) Besides, we were interested in the positions of codons (1st, 2nd and 3rd nucleotides) and its nucleotidic abundances. def getPosCodon(seq, letter, start): count = 0 for nucl in range(start, len(seq), 3): if seq[nucl] == letter: count += 1.0 return round(count/((len(seq)- seq.count(&quot;-&quot;))/3), ndigits=2) general = [] for start in range(3): df_nt = [] nt_pos_means = [] nt_pos_medians = [] nt_pos_std = [] for i, nucleot in enumerate(letters): NT_content = [] for alignment in paths: name = alignment[0:alignment.find(&quot;_&quot;)] if len(name) &gt; 50: name = &quot;p22 core&quot; for record in SeqIO.parse(alignment, &quot;fasta&quot;): count = getPosCodon(str(record.seq), nucleot, start) NT_content.append([count, name]) if nucleot == &quot;T&quot;: name = &quot;U&quot; + str(start + 1) else: name = nucleot + str(start + 1) df_nt.append(pd.DataFrame(NT_content, columns=[name, &quot;Sequence&quot;])) nt_pos_means.append(df_nt[i].groupby(&quot;Sequence&quot;).mean()) nt_pos_medians.append(df_nt[i].groupby(&quot;Sequence&quot;).median()) nt_pos_std.append(df_nt[i].groupby(&quot;Sequence&quot;).std()) general.append(nt_pos_medians) Now we join all data of nucleotides and plot a heatmap. nucleotides_matrix = pd.concat([nt_only_medians[0],nt_only_medians[1],nt_only_medians[2],nt_only_medians[3], general[0][0], general[0][1], general[0][2], general[0][3], general[1][0], general[1][1], general[1][2], general[1][3], general[2][0],general[2][1], general[2][2], general[2][3]], axis=1) fig, ax = plt.subplots() plt.rcParams[&quot;figure.figsize&quot;] = [20,1.5] nucleotides_matrix = nucleotides_matrix.reindex(index = [&#39;RdRp&#39;,&#39;CP&#39;,&#39;p19&#39;, &#39;p22&#39;, &#39;p22 core&#39;, &#39;other cores&#39;]) sns.heatmap(nucleotides_matrix, ax=ax, cmap=&quot;viridis&quot;) plt.xlabel(&quot;Nucleotide&quot;) plt.tight_layout() 5.3 Dinuclotides We read dinucleotides, calculate a relativized value and plot the medians. def read_diNT(path): chains_dint = SeqIO.parse(path, &quot;fasta&quot;) chain_dint_p22_core = [] for chain in chains_dint: dint = {} seq = str(chain.seq) for ch in range(len(seq)-1): dinuc = seq[ch:ch+2].replace(&quot;T&quot;, &quot;U&quot;) if dinuc in dint: dint[dinuc] += 1 else: if dinuc.find(&quot;-&quot;)&lt;0 and dinuc.find(&quot;N&quot;)&lt;0: dint[dinuc] = 1 chain_dint_p22_core.append(dint) return pd.DataFrame.from_dict(chain_dint_p22_core) def rel_diNT(df_dint): return df_dint.divide(df_dint.sum(axis=1), axis=0) def stats_composition(df_composition, stat=&quot;median&quot;): if stat == &quot;median&quot;: return pd.DataFrame.from_dict(df_composition.mean()) elif stat == &quot;mean&quot;: return pd.DataFrame.from_dict(df_composition.median()) elif stat == &quot;std&quot;: return pd.DataFrame.from_dict(df_composition.std()) def join_medians(median_df): dint_comparison = pd.concat([median_df[0], median_df[1], median_df[2], median_df[3], median_df[4], median_df[5][0][list(median_df[0].index)]], axis=1) dint_comparison.columns = [&quot;RdRp&quot;, &quot;CP&quot;, &quot;p19&quot;, &quot;p22&quot;, &quot;p22_core&quot;, &quot;other cores&quot;] return dint_comparison.T Then, we plot a heatmap with the shares of both nucleotides and nucleotides per codon position. # Paths of fasta files with nucleotide sequences paths = [&quot;RdRp_nt_aligned.fa&quot;, &quot;cp_nt_aligned.fa&quot;, &quot;p19_nt_aligned.fa&quot;, &quot;p22_nt_aligned.fa&quot;, &quot;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/concatenate/p22 core_nt_alignment.fa&quot;, &quot;other cores_nt.fa&quot;] order_names = [] median_df = [] for path in paths: df_dint = read_diNT(path) df_dint_rel = rel_diNT(df_dint) median_df.append(stats_composition(df_dint_rel)) summary_diNT = join_medians(median_df) fig, ax = plt.subplots() plt.rcParams[&quot;figure.figsize&quot;] = [12,1.5] sns.heatmap(summary_diNT,ax=ax, cmap=&quot;viridis&quot;) plt.xlabel(&quot;Dinucleotide&quot;) plt.tight_layout() 5.4 Codons We write the paths of the fasta files. concatenate_dir = &quot;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/concatenate/&quot; paths = [ concatenate_dir + &quot;RdRp_nt_aligned.fasta&quot;, concatenate_dir + &quot;cp_nt_aligned_filtered.fasta&quot;, concatenate_dir + &quot;p19_nt_alignment.fasta&quot;, concatenate_dir + &quot;p22_nt_alignment.fasta&quot;, concatenate_dir + &quot;p22 core_nt_alignment.fa&quot;, # concatenate_dir + &quot;union/sequence_data.fas&quot;, &quot;/Users/esmeralda/Documents/TFM/overlap_comparisons/other cores_nt.fa&quot;] names = [&quot;RdRp&quot;, &quot;CP&quot;, &quot;p19&quot;, &quot;p22&quot;, &quot;p22 core&quot;, &quot;other cores&quot;] The following steps consist of reading and counting codons. To emphasize the effect of codon usage we calculated the percentage of each codon within its group of codons that codify the same amino acid. For instance, if codons TGT and TGC are used 3 and 12 times, respectively, as both encode the amino acid C, the relative abundance is calculated as 0.2 for the former and 0.8 for the latter. Therefore, the comparison has to be made between different groups, but within the same amino acid. def read_codons(path): n = 3 record_dict = SeqIO.to_dict(SeqIO.parse(path, &quot;fasta&quot;)) codon_dict = {} for seq_name in record_dict.keys(): seq = str(record_dict[seq_name].seq) codon_dict[seq_name] = [seq[i:i+n] for i in range(0, len(seq), n)] return pd.DataFrame.from_dict(codon_dict) def count_codons(df_codons): counts = [] for column in df_codons.columns: counts_num = df_codons[column].value_counts() counts.append(counts_num) codon_abs = pd.DataFrame.from_dict(counts) codon_abs.fillna(0, inplace=True) return codon_abs def relative_codons(codon_matrix, table_DNA_to_codon): codon_rel = pd.DataFrame() for amino in table_DNA_to_codon.keys(): if len(table_DNA_to_codon[amino]) &gt; 1 and amino != &quot;STOP&quot;: total = codon_matrix[table_DNA_to_codon[amino]].sum(axis=1) res = codon_matrix[table_DNA_to_codon[amino]].div(total, axis=0) codon_rel = pd.concat([codon_rel, res], axis=1) return codon_rel def join_codons(list_dfs, names): for i in range(len(names)): list_dfs[i][&quot;Sequence&quot;] = names[i] return pd.concat([list_dfs[0], list_dfs[1], list_dfs[2], list_dfs[3], list_dfs[4], list_dfs[5]], axis=0).T.fillna(0, inplace=True) def join_codons_medians(list_dfs): return pd.concat([list_dfs[0].median(axis=0), list_dfs[1].median(axis=0), list_dfs[2].median(axis=0), list_dfs[3].median(axis=0), list_dfs[4].median(axis=0), list_dfs[5].median(axis=0)], axis = 1).T Now we run the functions. dfs_codons = [] for path in paths: codons = read_codons(path) codons_abs = count_codons(codons) if path.find(&quot;p22 core&quot;) &gt; 0: codons_abs[&quot;CGT&quot;] = 0.0 dfs_codons.append(relative_codons(codons_abs, table_DNA_to_codon)) df_codon_all = join_codons(dfs_codons, names=names) df_codons_medians = join_codons_medians(dfs_codons) Finally, we can get the heatmap with a seaborn function. plt.rcParams[&quot;figure.figsize&quot;] = [16, 2] fig, ax = plt.subplots(nrows=1) new_columns = [] for codon_name in df_codons_medians.columns: new = codon_name.replace(&quot;T&quot;, &quot;U&quot;) new_columns.append(new) df_codons_medians.columns = new_columns df_codons_medians.index = [&quot;RdRp&quot;, &quot;CP&quot;, &quot;p19&quot;, &quot;p22&quot;, &quot;p22 core&quot;, &quot;other cores&quot;] print(len(new_columns)) sns.heatmap(df_codons_medians, cmap=&quot;viridis&quot;) plt.xlabel(&quot;Codon&quot;) plt.xticks(rotation=45) plt.yticks(rotation=0) ax.yaxis.set_ticks_position(&#39;none&#39;) plt.tight_layout() This following code is useful to verify the significance between two groups. We use Mann-Whitney test to see if there is significance in the difference between p22 core and non-overlapping cores. df_codon_all.fillna(0, inplace=True) codon = &quot;CAT&quot; df_plot = df_codon_all.T[[codon, &quot;Sequence&quot;]] p22_core = list(df_plot[df_plot[&quot;Sequence&quot;] == &quot;p22 core&quot;][codon].values) other_cores = list(df_plot[df_plot[&quot;Sequence&quot;] == &quot;other cores&quot;][codon].values) pvalues = [ scipy.stats.mannwhitneyu(p22_core, other_cores, alternative=&quot;two-sided&quot;).pvalue ] formatted_pvalues = [f&#39;p={pvalue:.2e}&#39; for pvalue in pvalues] Then, we plot the data and the significance too. plt.rcParams[&quot;figure.figsize&quot;] = [16,9] sns.set_style(&quot;white&quot;) colors = sns.color_palette(&quot;colorblind&quot;, 5) fig, ax = plt.subplots() pairs = [(&#39;p22 core&#39;, &#39;other cores&#39;)] with sns.plotting_context(&#39;notebook&#39;, font_scale = 1.2): sns.swarmplot(data=df_plot, x=&quot;Sequence&quot;, y=codon, ax=ax, palette=colors) sns.boxplot(data=df_plot, x=&quot;Sequence&quot;, y=codon, zorder=0, dodge=True, ax=ax, boxprops={&#39;facecolor&#39;:&#39;None&#39;}) # Add annotations annotator = Annotator(ax=ax, pairs = pairs, data=df_plot, x=&quot;Sequence&quot;, y=codon) annotator.set_custom_annotations(formatted_pvalues) annotator.configure(test_short_name=&quot;MWW&quot;) # text_format is still simple annotator.set_pvalues_and_annotate(pvalues) "],["comparative-analyses-of-selection.html", "Chapter 6 Comparative analyses of selection 6.1 Evolution speed with aBSREL 6.2 FEL for correlations", " Chapter 6 Comparative analyses of selection 6.1 Evolution speed with aBSREL Here we take advantage of the complete sequences of tombusvirus genomes available in NCBI. We use the adaptive branch-site random effects likelihood (aBSREL) method to estimate the omega = dN/dS rates ratio per branch for p19 and p22 as well as for RdRp as a reference. For each branch, estimated omega p19 and omega p22 values are normalized by the corresponding omega RdRp values, so all branches were brought to a common relative scale and asinh-transformed: œâ_x^=œâ_x‚ÅÑœâ_RdRp with x ÔÉé {p19, p22}. 6.1.1 Libraries and json files import json import numpy as np import pandas as pd import scipy.stats from statannotations.Annotator import Annotator First, we need to read the json files that contain the results of aBSREL with different genes from the same genomes. # Read json files of each gene paths = [path_p22, path_p19, path_RdRp, path_cp] for path in paths: df = read_branches(path) dfs.append(add_info(df, significance)) 6.1.2 Omega and significance Afterwards, information about the significance is added and the overall omega is calculated. Besides, we need to detect what nodes are missing in the output of aBSREL and then, we define them as null and non-significative. def add_info(data, significance): data[&#39;omega_avg&#39;] = (data[&#39;omega1&#39;]*data[&#39;prop1&#39;]) + (data[&#39;omega2&#39;]*data[&#39;prop2&#39;]) data[&quot;signif&quot;] = np.where(data[&#39;pvalue&#39;] &lt; significance, True, False) return data def fill_missing_nodes(data, missing_nodes): for i in missing_nodes: new_row = {&quot;name&quot;: i, &quot;type&quot; : &quot;Node&quot;, &quot;omega1&quot;: 0.0, &quot;prop1&quot; : 0.0, &quot;omega2&quot;: 0.0, &quot;prop2&quot; : 0.0, &quot;pvalue&quot; : 1.0, &quot;omega_avg&quot; : 0.0, &quot;Signif.&quot; : False} data = data.append(new_row, ignore_index=True) return data 6.1.3 Relative asinh transformation Next step consists of calculating the relative measure for comparing the different genes, based on an asinh transformation. def relativize(genes, gene_ref): results = [] type_tree = [] for i in range(3): results_gene = [] for name in gene_ref[&quot;name&quot;]: omega_x = float(genes[i][genes[i][&quot;name&quot;] == name][&quot;omega_avg&quot;]) omega_std = float(gene_ref[gene_ref[&quot;name&quot;] == name][&quot;omega_avg&quot;]) results_gene.append(np.log(omega_x + (np.sqrt(omega_x**2 + 1))/(omega_std + (np.sqrt(omega_std**2 + 1))))) results.append(results_gene) return results 6.1.4 Utilities Some other functions are employed in order to change the structure of data for its visualization and other to calculate p values with Wilcoxon-Mann-Whitney test. def divide_branches(results, gene_ref): pos_tips = gene_ref.index[gene_ref[&#39;type&#39;] == &quot;Tip&quot;].tolist() tips = [] nodes = [] for gene in range(3): tip_selection = [] node_selection = [] for i, value in enumerate(results[gene]): if i in pos_tips: tip_selection.append(value) else: node_selection.append(value) tips.append(tip_selection) nodes.append(node_selection) return (tips, nodes) def calc_pvalues(chunk): pvalues_tips = [scipy.stats.wilcoxon(chunk[0], chunk[1], alternative=&quot;two-sided&quot;).pvalue, # p22 vs p19 scipy.stats.wilcoxon(chunk[0], chunk[2], alternative=&quot;two-sided&quot;).pvalue, # p22 vs CP scipy.stats.wilcoxon(chunk[1], chunk[2], alternative=&quot;two-sided&quot;).pvalue] # p19 vs CP return pvalues_tips def format_pvalues(pvalues_1to1): return [[f&#39;p={pvalue:.3e}&#39; for pvalue in pvalues_1to1[0]], [f&#39;p={pvalue:.3e}&#39; for pvalue in pvalues_1to1[1]], [f&#39;p={pvalue:.3e}&#39; for pvalue in pvalues_1to1[2]]] def info_to_dataframe(data): return pd.DataFrame.from_dict({&quot;omega&quot;: data[0] + data[1] + data[2], &quot;Gene&quot; : len(data[0])*[&#39;p22&#39;] + len(data[0])*[&#39;p19&#39;] + len(data[0])*[&#39;CP&#39;]}) 6.1.5 Boxplots with significance Two different plots can be generated with the following plots. The first one includes all, only nodes (or branches) and only tips, while the second is only focused on the whole tree. Both includes p-value annotation. def plot_diff_types(data, pvalues_1to1, formatted_pvalues): colors = sns.color_palette(&quot;colorblind&quot;, 5) fig, ax = plt.subplot_mosaic(&quot;ABC&quot;, figsize = (20,8)) axes = [ax[&quot;A&quot;], ax[&quot;B&quot;], ax[&quot;C&quot;]] annot = [] pairs = [(&quot;p22&quot;, &quot;p19&quot;),(&quot;p22&quot;, &quot;CP&quot;), (&quot;p19&quot;, &quot;CP&quot;)] titles = [&quot;TIPS&quot;, &quot;BRANCHES&quot;, &quot;TREE&quot;] for part in range(len(data)): with sns.plotting_context(&#39;notebook&#39;, font_scale = 1.2): sns.swarmplot(data=data[part], x=&quot;Gene&quot;, y=&quot;omega&quot;, ax=axes[part],palette=colors, zorder=0) sns.boxplot(data=data[part], x=&quot;Gene&quot;, y=&quot;omega&quot;, dodge=True, ax=axes[part], boxprops={&#39;facecolor&#39;:&#39;None&#39;}) axes[part].set_title(titles[part]) plt.axhline(1) # Add annotations annot.append(Annotator(ax=axes[part], pairs = pairs, data=data[part], x=&quot;Gene&quot;, y=&quot;omega&quot;)) annot[part].set_custom_annotations(formatted_pvalues[part]) annot[part].configure(test_short_name=&quot;MWW&quot;) # text_format is still simple annot[part].set_pvalues_and_annotate(pvalues_1to1[part]) plt.tight_layout(pad=1.5) plt.show() def plot_one_type(data, pvalues_1to1, formatted_pvalues, one): colors = [&quot;#9867F4&quot;, &quot;#FFD500&quot;] plt.style.use(&quot;default&quot;) fig, ax = plt.subplots(figsize = (6,12)) part = 2 # 2: tree annot = [] pairs = [(&quot;p22&quot;, &quot;p19&quot;)] size_labels = 24 with sns.plotting_context(&#39;notebook&#39;, font_scale = 1.2): sns.set(font_scale=4) sns.swarmplot(data=data[part][data[part][&quot;Gene&quot;] != &quot;CP&quot;], x=&quot;Gene&quot;, y=&quot;omega&quot;, palette=colors, zorder=0) sns.boxplot(data=data[part][data[part][&quot;Gene&quot;] != &quot;CP&quot;], x=&quot;Gene&quot;, y=&quot;omega&quot;, dodge=True, boxprops={&#39;facecolor&#39;:&#39;None&#39;}) plt.axhline(0, color=&#39;grey&#39;, linestyle=&#39;dotted&#39;) ax.set_xlabel(&quot;Gene sequence&quot;, fontsize = size_labels) ax.set_ylabel(&quot;Transformed omega ratio&quot;, fontsize = size_labels) ax.yaxis.set_tick_params(labelsize = size_labels - 1) ax.xaxis.set_tick_params(labelsize = size_labels - 1) # Add annotations annot = Annotator(ax=ax, pairs = pairs, data=data[part][data[part][&quot;Gene&quot;] != &quot;CP&quot;], x=&quot;Gene&quot;, y=&quot;omega&quot;) annot.set_custom_annotations([formatted_pvalues[part][one]]) annot.configure(test_short_name=&quot;MWW&quot;) # text_format is still simple annot.set_pvalues_and_annotate([pvalues_1to1[part][one]]) plt.tight_layout(pad=1.5) # plt.savefig(&quot;/Users/esmeralda/Documents/TFM/article/omegaratio.pdf&quot;, format= &quot;pdf&quot;) plt.show() 6.1.6 Test selection Finally, we determine whether the omega values are different from zero (no selection). def test_one(df_values, mean): results_test = {&quot;Tips:&quot;: [scipy.stats.ttest_1samp(df_values[0][0], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[0][1], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[0][2], popmean=mean).pvalue], &quot;Branches:&quot;: [scipy.stats.ttest_1samp(df_values[1][0], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[1][1], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[1][2], popmean=mean).pvalue], &quot;Tree&quot;: [scipy.stats.ttest_1samp(df_values[2][0], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[2][1], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[2][2], popmean=mean).pvalue]} df = pd.DataFrame.from_dict(results_test) df.index = [&quot;p22&quot;, &quot;p19&quot;, &quot;CP&quot;] return df 6.1.7 Run def main(): dfs = [] significance = 0.1 path_p22 = &#39;p22_nt_alignment.fasta.ABSREL.json&#39; path_p19 = &#39;p19_nt_alignment.fasta.ABSREL.json&#39; path_RdRp = &#39;RdRp_nt_alignment.fasta.ABSREL.json&#39; path_cp = &#39;cp_nt_alignment.fasta.ABSREL.json&#39; # Read json files of each gene paths = [path_p22, path_p19, path_RdRp, path_cp] for path in paths: df = read_branches(path) dfs.append(add_info(df, significance)) # Filling missing nodes with zero values missing_nodes_p22 = [&quot;Node11&quot;, &quot;Node18&quot;, &quot;Node6&quot;] missing_nodes_p19 = [&quot;Node11&quot;, &quot;Node18&quot;, &quot;Node3&quot;, &quot;Node6&quot;] df_p22 = fill_missing_nodes(dfs[0], missing_nodes_p22) df_p19 = fill_missing_nodes(dfs[1], missing_nodes_p19) df_RdRp = dfs[2] df_cp = dfs[3] # Generate relative values for all, tips and nodes genes = [df_p22, df_p19, df_cp] results = relativize(genes, df_RdRp) tips, nodes = divide_branches(results, df_RdRp) # Calculate pvalues in pairs pvalues_1to1 = [] df_values = [] sep_types = [tips, nodes, results] for chunk in sep_types: pvalues_1to1.append(calc_pvalues(chunk)) df_values.append(info_to_dataframe(chunk)) # Get formatted pvalues formatted_pvalues = format_pvalues(pvalues_1to1) # Boxplots with significance plot_diff_types(df_values, pvalues_1to1, formatted_pvalues) plot_one_type(df_values, pvalues_1to1, formatted_pvalues, 0) # T test one sample vs mean = 0 print(test_one(sep_types, 0)) 6.2 FEL for correlations In this section, we read json files of p19 and p22 analysis, generated with FEL method of Hyphy. The objective here is to obtain correlations between selection and infer in which measure the correlation is determined by the secondary structure of the proteins both encode. ###Libraries and json files import json import matplotlib.pyplot as plt import numpy as np import pandas as pd import scipy.stats import seaborn as sns First, we need to read the json files that contain the results of FEL with both genes. def read_json(path): with open(path) as user_file: file_contents = user_file.read() parsed_json = json.loads(file_contents) values = {&quot;codon&quot;: list(range(len(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;]))), &quot;alpha&quot;: [], &quot;beta&quot;: [], &quot;pvalue&quot;: []} for i in range(len(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;])): values[&#39;alpha&#39;].append(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;][i][0]) values[&#39;beta&#39;].append(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;][i][1]) values[&#39;pvalue&#39;].append(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;][i][4]) return pd.DataFrame.from_dict(values) 6.2.1 Significance and difference Now, information about significance and the difference between the estimated rates of non-synonymous (beta) and synonymous (alpha) substitutions are added. def add_info(data, significance): data[&#39;beta - alpha&#39;] = data[&#39;beta&#39;] - data[&#39;alpha&#39;] data[&quot;signif&quot;] = np.where(data[&#39;pvalue&#39;] &lt; significance, True, False) return data We can even print the codon positions that are detected under selection significantly. def significative_codons(data): return (list(data[(data[&quot;signif&quot;] == True) &amp; (data[&quot;beta - alpha&quot;] &gt; 0)].index + 1) +\\ list(data[(data[&quot;signif&quot;] == True) &amp; (data[&quot;beta - alpha&quot;] &lt; 0)].index + 1)) 6.2.2 Plot correlation As we know the frameshift of one gene, we can plot selection values (here the difference beta-alpha) by positions in p19 and p22. Besides, we can mark the significance by colors. def plot_correlation(data1, data2, shift, colors): plt.style.use(&#39;default&#39;) fig = plt.figure(figsize=(6,12)) ax = fig.add_subplot(111) fontsize = 24 points_size = 20 plt.ylim(-14,11) plt.xlim(-16,7) plt.scatter(data2[&quot;beta - alpha&quot;][shift:len(data1[&quot;beta - alpha&quot;]) + shift], data1[&quot;beta - alpha&quot;], s=points_size, c=colors) plt.xlabel(&quot;$\\\\beta$ - $\\\\alpha$ (p22)&quot;) plt.ylabel(&quot;$\\\\beta$ - $\\\\alpha$ (p19)&quot;) plt.axhline(0,color=&#39;black&#39;, linewidth=1, ls=&quot;--&quot;, alpha=0.5) # x = 0 plt.axvline(0,color=&#39;black&#39;, linewidth=1, ls=&quot;--&quot;, alpha=0.5) # x = 0 ax.xaxis.label.set_fontsize(fontsize) ax.yaxis.label.set_fontsize(fontsize) plt.xticks(fontsize=fontsize - 1) plt.yticks(fontsize=fontsize - 1) plt.tight_layout(pad=1.5) plt.show() def define_colors(data1, data2): color_p19 = &quot;#FFD500&quot; color_p22 = &quot;#9867F4&quot; color_both = &quot;#242038&quot; others = &quot;#A2A2A2&quot; colors = [] for i in range(len(data1)): if data1[&quot;signif&quot;][i] and data2[&quot;signif&quot;][i]: colors.append(color_both) elif data2[&quot;signif&quot;][i]: colors.append(color_p22) elif data1[&quot;signif&quot;][i]: colors.append(color_p19) else: colors.append(others) return colors 6.2.3 Test correlation of selection After creating a combined dataframe based on the shift between both genes, we proceed to search correlation including all values or those that were significant (of p19, p22, both or at least one of them). We found that there could be a linear dependence in the upper left quadrant, so a Pearson correlation coefficient and its corresponding p value are calculated. def combine_genes(data1, data2, shift): combi = pd.DataFrame() combi[&quot;p22 diff&quot;] = list(data2[&quot;beta - alpha&quot;][shift:len(data1[&quot;beta - alpha&quot;]) + shift]) combi[&quot;p19 diff&quot;] = list(data1[&quot;beta - alpha&quot;]) combi[&quot;p22_signif&quot;] = list(data2[&quot;signif&quot;][shift:len(data1[&quot;beta - alpha&quot;]) + shift]) combi[&quot;p19_signif&quot;] = list(data1[&quot;signif&quot;]) return combi def search_correlation(combi, num): if num == 0: # ALL corr = correl_total(combi) elif num == 1: # p19 corr = correl_one(combi, num) elif num == 2: # p22 corr = correl_one(combi, num) elif num == 3: # At least one corr = correl_least_one(combi) else: # Both significative corr = correl_both(combi) return (corr, scipy.stats.fisher_exact(corr)) def correl_total(combi): total = [[len(combi[(combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)]), len(combi[(combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)])], [len(combi[(combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)]), len(combi[(combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)])]] return total def correl_least_one(combi): one_atleast = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])]] return one_atleast def correl_both(combi): both_sig_table = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] &amp; combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])]] return both_sig_table def correl_one(combi, num): if num == 1: sig_table = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p19_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p19_signif&quot;]))])]] else: sig_table = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;]))])]] return sig_table def pearson_upper_left(combi): upper_left = combi[(combi[&quot;p19 diff&quot;] &gt; 0) &amp; (combi[&quot;p22 diff&quot;] &lt; 0)] y = upper_left[&quot;p19 diff&quot;] x = upper_left[&quot;p22 diff&quot;] return scipy.stats.pearsonr(x, y) 6.2.4 Correlation 2D Another point to be inquired is the possible correlation between secondary structure of both proteins. def corr_struct(struct1, struct2, shift): combinations_3d = pd.DataFrame(0, columns=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;], index=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;]) for pos in range(len(struct1)): combinations_3d[struct2[pos+shift]][struct1[pos]] += 1 res = list(scipy.stats.chi2_contingency(combinations_3d)) res.append(combinations_3d) return res The resulting table of contingency can be plotted to show with colors where and how is the data distribution. It can be also combined with the expected frequencies and therefore, we can plot a table with the ratio real/expected, what can be very informative too. def plot_dist_3D(combinations_3d, expected=0): if isinstance(expected, int): data = combinations_3d else: data = combinations_3d / pd.DataFrame(expected, columns=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;], index=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;]) plt.figure(figsize=(8, 6)) sns.heatmap(data, annot=True, cmap=&#39;YlGnBu&#39;) plt.xlabel(&#39;p22&#39;) plt.ylabel(&#39;p19&#39;) plt.show() 6.2.5 Selection in 2D This additional division aims to focus the attention on the secondary structures separately. With the following function, nine contingency tables 3x3 are calculated considering neutral, positive and negative selection in both frames. The difference between these tables is the exclusive presence of codons that belong to regions which form helices, strands or loops (or all). def selection_structure(p19_struct, p22_struct, df_p19, df_p22, comparison_letters, shift): macro_results = [] for letters in comparison_letters: result = pd.DataFrame(0, columns = [&quot;Neg.&quot;, &quot;Pos.&quot;, &quot;-&quot;], index = [&quot;Neg.&quot;, &quot;Pos.&quot;, &quot;-&quot;]) for i in range(len(p19_struct)): if p19_struct[i] == letters[0] and p22_struct[i+shift] == letters[1]: p19_value = df_p19[&quot;beta - alpha&quot;][i] p22_value = df_p22[&quot;beta - alpha&quot;][i+shift] if p19_value == 0 and p22_value == 0: result[&quot;-&quot;][&quot;-&quot;] += 1 elif p19_value == 0 and p22_value &gt; 0: result[&quot;Pos.&quot;][&quot;-&quot;] += 1 elif p19_value == 0 and p22_value &lt; 0: result[&quot;Neg.&quot;][&quot;-&quot;] += 1 elif p19_value &gt; 0 and p22_value == 0: result[&quot;-&quot;][&quot;Pos.&quot;] += 1 elif p19_value &lt; 0 and p22_value == 0: result[&quot;-&quot;][&quot;Neg.&quot;] += 1 elif p19_value &gt; 0 and p22_value &gt; 0: result[&quot;Pos.&quot;][&quot;Pos.&quot;] += 1 elif p19_value &lt; 0 and p22_value &lt; 0: result[&quot;Neg.&quot;][&quot;Neg.&quot;] += 1 elif p19_value &gt; 0 and p22_value &lt; 0: result[&quot;Neg.&quot;][&quot;Pos.&quot;] += 1 elif p19_value &lt; 0 and p22_value &gt; 0: result[&quot;Pos.&quot;][&quot;Neg.&quot;] += 1 macro_results.append(result) return macro_results 6.2.6 Run Notice that we indicate for every position of p19 and p22 the corresponding secondary structure. H: helix, S:strand and L: loop. def main(): path_p19 = &#39;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/FEL_p19_local/p19_FEL.json&#39; path_p22 = &#39;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/FEL_p22_local/firts.json&#39; # Read json files and add information significance = 0.1 df_p19 = add_info(read_json(path_p19), significance) df_p22 = add_info(read_json(path_p22), significance) # Print significative codons print(&quot;Signif. p19:&quot;, significative_codons(df_p19), &quot;Signif. p22:&quot;, significative_codons(df_p22)) # Plot dots +10 and +11 codons colors = define_colors(df_p19, df_p22) plot_correlation(df_p19, df_p22, 10, colors) plot_correlation(df_p19, df_p22, 11, colors) # Combine both sequences with a shift p19_p22 = combine_genes(df_p19, df_p22, 10) # Search correlations correlations = [&quot;All&quot;, &quot;Only p19 significant&quot;, &quot;Only p22 significant&quot;, &quot;At least one significant&quot;, &quot;Both significant&quot;] for option in range(5): len_hyphen = (50-len(correlations[option]))//2 print(&quot;-&quot;*len_hyphen, correlations[option], &quot;-&quot;*len_hyphen) res = search_correlation(p19_p22, option) print(&quot;Contingency table:\\n&quot;, res[0]) print(&quot;Statistic (Fisher&#39;s exact test):\\n&quot;, res[0][0]) print(&quot;p value (Fisher&#39;s exact test):\\n&quot;, res[0][1]) # Pearson correlation correlation_coef, p_value = pearson_upper_left(p19_p22) print(&quot;Pearson correlation coefficient:&quot;, correlation_coef) print(&quot;p-value:&quot;, p_value) # Info structure order = [&quot;H&quot;, &quot;S&quot;, &quot;L&quot;] p22_struct = [&quot;L&quot;]*16 + [&quot;S&quot;]*4 + [&quot;L&quot;]*4 + [&quot;S&quot;]*4 + [&quot;L&quot;]*6 + [&quot;S&quot;]*3 +\\ [&quot;L&quot;]*3 + [&quot;H&quot;]*10 + [&quot;L&quot;]*4 + [&quot;S&quot;]*13 + [&quot;L&quot;]*10 + [&quot;S&quot;]*5 +\\ [&quot;L&quot;]*9 + [&quot;S&quot;]*3 + [&quot;L&quot;]*9 + [&quot;S&quot;]*5 + [&quot;L&quot;]*15 + [&quot;S&quot;]*5 +\\ [&quot;L&quot;]*10 + [&quot;S&quot;]*14 + [&quot;L&quot;]*11 + [&quot;S&quot;]*4 + [&quot;H&quot;]*20 + [&quot;L&quot;]*2 p19_struct = [&quot;L&quot;]*5 + [&quot;H&quot;]*13 + [&quot;L&quot;]*19 + [&quot;H&quot;]*9 + [&quot;L&quot;]*11 + [&quot;S&quot;]*8 +\\ [&quot;L&quot;]*2 + [&quot;S&quot;]*8 + [&quot;L&quot;]*3 + [&quot;H&quot;]*10 + [&quot;L&quot;]*2 + [&quot;H&quot;]*11 +\\ [&quot;L&quot;]*7 + [&quot;S&quot;]*8 + [&quot;L&quot;]*2 + [&quot;S&quot;]*8 + [&quot;L&quot;]*2 + [&quot;H&quot;]*17 +\\ [&quot;L&quot;]*27 # (+10) Combinations 3D; Columns: p22 ; Rows: p19 ; PLOT chi2_stat, p_value, dof, expected, cont_table= \\ corr_struct(p19_struct, p22_struct, 10) expected = pd.DataFrame(expected, index=order, columns=order) print(&quot;+10\\nChi-Square Statistic:&quot;, chi2_stat) print(&quot;P-value:&quot;, p_value) print(&quot;Degrees of Freedom:&quot;, dof) print(&quot;Expected Frequencies:\\n&quot;, expected, &quot;\\nCounts:\\n&quot;, cont_table) plot_dist_3D(cont_table) plot_dist_3D(cont_table, expected) # (+11) Combinations 3D; Columns: p22 ; Rows: p19 ; PLOT chi2_stat, p_value, dof, expected, cont_table = \\ corr_struct(p19_struct, p22_struct, 11) expected = pd.DataFrame(expected, index=order, columns=order) print(&quot;+11\\nChi-Square Statistic:&quot;, chi2_stat) print(&quot;P-value:&quot;, p_value) print(&quot;Degrees of Freedom:&quot;, dof) print(&quot;Expected Frequencies:\\n&quot;, expected, &quot;\\nCounts:\\n&quot;, cont_table) plot_dist_3D(cont_table) plot_dist_3D(cont_table, expected) # Comparison selection structure comparison_letters = [(&quot;H&quot;, &quot;H&quot;), (&quot;H&quot;, &quot;S&quot;), (&quot;H&quot;, &quot;L&quot;), (&quot;S&quot;, &quot;S&quot;), (&quot;S&quot;, &quot;L&quot;), (&quot;S&quot;, &quot;H&quot;), (&quot;L&quot;, &quot;L&quot;), (&quot;L&quot;, &quot;S&quot;), (&quot;L&quot;, &quot;H&quot;)] list_tables = selection_structure(p19_struct, p22_struct, df_p19, df_p22, comparison_letters, 10) print(25*&quot;-&quot; + &quot;+10&quot; + 25*&quot;-&quot;) for pos, res in enumerate(comparison_letters): print(&quot;\\nComparison:&quot;, res) print(list_tables[pos]) list_tables = selection_structure(p19_struct, p22_struct, df_p19, df_p22, comparison_letters, 11) print(25*&quot;-&quot; + &quot;+11&quot; + 25*&quot;-&quot;) for pos, res in enumerate(comparison_letters): print(&quot;\\nComparison:&quot;, res) print(list_tables[pos]) if __name__ == &quot;__main__&quot;: main() "],["miscellania.html", "Chapter 7 Miscellania 7.1 Representation of predicted disordered amino acid data", " Chapter 7 Miscellania Here you can find out how we implement the visualization of different issues in Python. 7.1 Representation of predicted disordered amino acid data We import some libraries. import matplotlib.pyplot as plt import pandas as pd import seaborn as sns Now we read a csv file with disordered data and few other characteristics of each protein. df_disorder = pd.read_csv(&quot;/Users/esmeralda/Documents/TFM/article/disorder_data.csv&quot;, sep=&quot;;&quot;) df_disorder[&#39;Length&#39;] = pd.to_numeric(df_disorder[&#39;Length&#39;], errors=&#39;coerce&#39;) We define for the following plots in Seaborn: The style The palette # Set Seaborn style to match a similar style to Plotly sns.set(rc={&#39;axes.facecolor&#39;: &#39;white&#39;, &#39;axes.edgecolor&#39;: &#39;white&#39;, &quot;axes.grid&quot;: True, &quot;grid.linestyle&quot;: &quot;--&quot;, &quot;font.size&quot;: 15, &quot;axes.labelsize&quot;: 15, &quot;xtick.labelsize&quot;: 12, &quot;ytick.labelsize&quot;: 12, &#39;xtick.bottom&#39;: True, &#39;figure.facecolor&#39;: &#39;white&#39;, &#39;xtick.top&#39;: False, &#39;xtick.bottom&#39;: False, &#39;ytick.left&#39;: True, &#39;ytick.right&#39;: False, &quot;grid.color&quot;: &quot;#DFDFDF&quot;, &#39;font.sans-serif&#39;: &#39;Helvetica&#39;}) safe_colorblind_palette = [&quot;#E69F00&quot;, &quot;#6D0000&quot;, &quot;#56B4E9&quot;, &quot;#97E4CF&quot;, &quot;#F0E442&quot;, &quot;#0F425F&quot;, &quot;#D55E00&quot;, &quot;#000877&quot;, &quot;#CA4E93&quot;, &quot;#ABB6D3&quot;, &quot;#D9F221&quot;] # Create a figure and axes plt.figure(figsize=(10, 6)) ax = sns.boxplot(data=df_disorder[df_disorder[&quot;Movement protein&quot;] == &quot;Movement protein&quot;], x=&quot;Taxonomy origin&quot;, y=&quot;Percentage&quot;, color=&quot;white&quot;, boxprops=dict(edgecolor=&#39;black&#39;), whiskerprops=dict(color=&#39;black&#39;), medianprops=dict(color=&#39;black&#39;), capprops=dict(linewidth=2), width=0.7, linewidth=0.6) marker_style = [] for i in df_disorder[&quot;Movement protein&quot;]: if i == &#39;o&#39;: marker_style.append(&#39;o&#39;) else: marker_style.append(&#39;X&#39;) We can plot disorder data classified by taxonomic families. ax = sns.swarmplot(data=df_disorder, x=&quot;Taxonomy origin&quot;, y=&quot;Percentage&quot;, color=&quot;black&quot;, palette=safe_colorblind_palette, size=7, marker=&quot;X&quot;) ax = sns.swarmplot(data=df_disorder[df_disorder[&quot;Movement protein&quot;] == &quot;Movement protein&quot;], x=&quot;Taxonomy origin&quot;, y=&quot;Percentage&quot;, color=&quot;black&quot;, palette=safe_colorblind_palette, marker=&quot;o&quot;, size=7) # Set plot labels and title plt.xlabel(&quot;Genus&quot;) plt.ylabel(&quot;% predicted disodered residues&quot;) # Adjust plot layout plt.xticks(rotation=45) plt.tight_layout() plt.savefig(&quot;percentage_taxonomy.pdf&quot;, format=&quot;pdf&quot;) # Display the plot plt.show() In this case, we plot all the proteins only divided by if their corresponding open reading frames are overprinted. safe_colorblind_palette_2 = [&quot;#054C6F&quot;, &quot;#44AA99&quot;] # Create a figure and axes plt.figure(figsize=(5, 6)) ax = sns.boxplot(data=df_disorder[df_disorder[&quot;Movement protein&quot;] == &quot;Movement protein&quot;], x=&quot;Overlap&quot;, y=&quot;Percentage&quot;, color=&quot;white&quot;, boxprops=dict(edgecolor=&#39;black&#39;), whiskerprops=dict(color=&#39;black&#39;), medianprops=dict(color=&#39;black&#39;), capprops=dict(linewidth=2), width=0.7, linewidth=0.6) ax = sns.swarmplot(data=df_disorder, x=&quot;Overlap&quot;, y=&quot;Percentage&quot;, color=&quot;black&quot;, palette=safe_colorblind_palette_2, marker=&quot;X&quot;, size=7) ax = sns.swarmplot(data=df_disorder[df_disorder[&quot;Movement protein&quot;] == &quot;Movement protein&quot;], x=&quot;Overlap&quot;, y=&quot;Percentage&quot;, color=&quot;black&quot;, palette=safe_colorblind_palette_2, marker=&quot;o&quot;, size=7) # Set plot labels and title plt.xlabel(&quot;&quot;) plt.ylabel(&quot;% predicted disodered residues&quot;) # Adjust plot layout plt.xticks(rotation=45) plt.tight_layout() plt.savefig(&quot;percentage_overprinted.pdf&quot;, format=&quot;pdf&quot;) # Display the plot plt.show() Then, we can also scatter the data, using the length of our proteins. plt.figure(figsize=(8, 6)) markers = {&quot;Movement protein&quot;: &quot;o&quot;, &quot;p19&quot;: &quot;X&quot;} sns.scatterplot(data=df_disorder, x=&#39;Length&#39;, y=&#39;Disordered residues&#39;, hue=&#39;Taxonomy origin&#39;, style=&quot;Movement protein&quot;, markers=markers, palette=safe_colorblind_palette, s=40) plt.legend([],[], frameon=False) plt.xlabel(&quot;Length&quot;) plt.ylabel(&quot;Predicted disordered residues&quot;) plt.savefig(&quot;disorder_scatter_taxonomy_legend.pdf&quot;, format=&quot;pdf&quot;) plt.show() Last, but not least, the previous plot can be only colored by the fact of if they were overprinted or not. plt.figure(figsize=(8, 6)) ax = sns.scatterplot(data=df_disorder, x=&#39;Length&#39;, y=&#39;Disordered residues&#39;, hue=&#39;Overlap&#39;,style=&quot;Movement protein&quot;, palette=safe_colorblind_palette_2, s=40) plt.xlabel(&quot;Length&quot;) plt.ylabel(&quot;Predicted disordered residues&quot;) plt.legend([],[], frameon=False) plt.savefig(&quot;disorder_scatter_overlap_legend.pdf&quot;, format=&quot;pdf&quot;) plt.show() "],["references.html", "References", " References "]]
