[["comparative-analyses-of-selection.html", "Chapter 6 Comparative analyses of selection 6.1 Evolution speed with aBSREL 6.2 FEL for correlations", " Chapter 6 Comparative analyses of selection 6.1 Evolution speed with aBSREL Here, we leverage the complete sequences of tombusvirus genomes available in NCBI. Using the adaptive branch-site random effects likelihood (aBSREL) method (Kosakovsky Pond and Frost 2005), we estimate the omega (dN/dS rates ratio) per branch for p19 and p22, with RdRp as a reference. For each branch, the estimated omega values for p19 and p22 are normalized by the corresponding omega values for RdRp. This normalization brings all branches to a common relative scale, and the values are then asinh-transformed: ω_x^=ω_x⁄ω_RdRp with x  {p19, p22}. 6.1.1 Libraries and json files import json import numpy as np import pandas as pd import scipy.stats from statannotations.Annotator import Annotator First, we need to read the JSON files containing the results of aBSREL for different genes from the same genomes. # Read json files of each gene paths = [path_p22, path_p19, path_RdRp, path_cp] for path in paths: df = read_branches(path) dfs.append(add_info(df, significance)) 6.1.2 Omega and significance Afterwards, we add significance information, and calculate the overall omega. Additionally, we identify nodes that are missing in the output of aBSREL. These nodes are then defined as null and non-significant. def add_info(data, significance): data[&#39;omega_avg&#39;] = (data[&#39;omega1&#39;]*data[&#39;prop1&#39;]) + (data[&#39;omega2&#39;]*data[&#39;prop2&#39;]) data[&quot;signif&quot;] = np.where(data[&#39;pvalue&#39;] &lt; significance, True, False) return data def fill_missing_nodes(data, missing_nodes): for i in missing_nodes: new_row = {&quot;name&quot;: i, &quot;type&quot; : &quot;Node&quot;, &quot;omega1&quot;: 0.0, &quot;prop1&quot; : 0.0, &quot;omega2&quot;: 0.0, &quot;prop2&quot; : 0.0, &quot;pvalue&quot; : 1.0, &quot;omega_avg&quot; : 0.0, &quot;Signif.&quot; : False} data = data.append(new_row, ignore_index=True) return data 6.1.3 Relative asinh transformation The next step consists of calculating the relative measure for comparing different genes, using an asinh transformation. def relativize(genes, gene_ref): results = [] type_tree = [] for i in range(3): results_gene = [] for name in gene_ref[&quot;name&quot;]: omega_x = float(genes[i][genes[i][&quot;name&quot;] == name][&quot;omega_avg&quot;]) omega_std = float(gene_ref[gene_ref[&quot;name&quot;] == name][&quot;omega_avg&quot;]) results_gene.append(np.log(omega_x + (np.sqrt(omega_x**2 + 1))/(omega_std + (np.sqrt(omega_std**2 + 1))))) results.append(results_gene) return results 6.1.4 Utilities Other functions are employed to restructure the data for visualization, while additional functions are used to calculate p-values using the Wilcoxon-Mann-Whitney test. def divide_branches(results, gene_ref): pos_tips = gene_ref.index[gene_ref[&#39;type&#39;] == &quot;Tip&quot;].tolist() tips = [] nodes = [] for gene in range(3): tip_selection = [] node_selection = [] for i, value in enumerate(results[gene]): if i in pos_tips: tip_selection.append(value) else: node_selection.append(value) tips.append(tip_selection) nodes.append(node_selection) return (tips, nodes) def calc_pvalues(chunk): pvalues_tips = [scipy.stats.wilcoxon(chunk[0], chunk[1], alternative=&quot;two-sided&quot;).pvalue, # p22 vs p19 scipy.stats.wilcoxon(chunk[0], chunk[2], alternative=&quot;two-sided&quot;).pvalue, # p22 vs CP scipy.stats.wilcoxon(chunk[1], chunk[2], alternative=&quot;two-sided&quot;).pvalue] # p19 vs CP return pvalues_tips def format_pvalues(pvalues_1to1): return [[f&#39;p={pvalue:.3e}&#39; for pvalue in pvalues_1to1[0]], [f&#39;p={pvalue:.3e}&#39; for pvalue in pvalues_1to1[1]], [f&#39;p={pvalue:.3e}&#39; for pvalue in pvalues_1to1[2]]] def info_to_dataframe(data): return pd.DataFrame.from_dict({&quot;omega&quot;: data[0] + data[1] + data[2], &quot;Gene&quot; : len(data[0])*[&#39;p22&#39;] + len(data[0])*[&#39;p19&#39;] + len(data[0])*[&#39;CP&#39;]}) 6.1.5 Boxplots with significance Two different plots can be generated using the following code. The first plot includes all elements, nodes (or branches), and tips, while the second plot is focused on the entire tree. Both plots include p-value annotations. def plot_diff_types(data, pvalues_1to1, formatted_pvalues): colors = sns.color_palette(&quot;colorblind&quot;, 5) fig, ax = plt.subplot_mosaic(&quot;ABC&quot;, figsize = (20,8)) axes = [ax[&quot;A&quot;], ax[&quot;B&quot;], ax[&quot;C&quot;]] annot = [] pairs = [(&quot;p22&quot;, &quot;p19&quot;),(&quot;p22&quot;, &quot;CP&quot;), (&quot;p19&quot;, &quot;CP&quot;)] titles = [&quot;TIPS&quot;, &quot;BRANCHES&quot;, &quot;TREE&quot;] for part in range(len(data)): with sns.plotting_context(&#39;notebook&#39;, font_scale = 1.2): sns.swarmplot(data=data[part], x=&quot;Gene&quot;, y=&quot;omega&quot;, ax=axes[part],palette=colors, zorder=0) sns.boxplot(data=data[part], x=&quot;Gene&quot;, y=&quot;omega&quot;, dodge=True, ax=axes[part], boxprops={&#39;facecolor&#39;:&#39;None&#39;}) axes[part].set_title(titles[part]) plt.axhline(1) # Add annotations annot.append(Annotator(ax=axes[part], pairs = pairs, data=data[part], x=&quot;Gene&quot;, y=&quot;omega&quot;)) annot[part].set_custom_annotations(formatted_pvalues[part]) annot[part].configure(test_short_name=&quot;MWW&quot;) # text_format is still simple annot[part].set_pvalues_and_annotate(pvalues_1to1[part]) plt.tight_layout(pad=1.5) plt.show() def plot_one_type(data, pvalues_1to1, formatted_pvalues, one): colors = [&quot;#9867F4&quot;, &quot;#FFD500&quot;] plt.style.use(&quot;default&quot;) fig, ax = plt.subplots(figsize = (6,12)) part = 2 # 2: tree annot = [] pairs = [(&quot;p22&quot;, &quot;p19&quot;)] size_labels = 24 with sns.plotting_context(&#39;notebook&#39;, font_scale = 1.2): sns.set(font_scale=4) sns.swarmplot(data=data[part][data[part][&quot;Gene&quot;] != &quot;CP&quot;], x=&quot;Gene&quot;, y=&quot;omega&quot;, palette=colors, zorder=0) sns.boxplot(data=data[part][data[part][&quot;Gene&quot;] != &quot;CP&quot;], x=&quot;Gene&quot;, y=&quot;omega&quot;, dodge=True, boxprops={&#39;facecolor&#39;:&#39;None&#39;}) plt.axhline(0, color=&#39;grey&#39;, linestyle=&#39;dotted&#39;) ax.set_xlabel(&quot;Gene sequence&quot;, fontsize = size_labels) ax.set_ylabel(&quot;Transformed omega ratio&quot;, fontsize = size_labels) ax.yaxis.set_tick_params(labelsize = size_labels - 1) ax.xaxis.set_tick_params(labelsize = size_labels - 1) # Add annotations annot = Annotator(ax=ax, pairs = pairs, data=data[part][data[part][&quot;Gene&quot;] != &quot;CP&quot;], x=&quot;Gene&quot;, y=&quot;omega&quot;) annot.set_custom_annotations([formatted_pvalues[part][one]]) annot.configure(test_short_name=&quot;MWW&quot;) # text_format is still simple annot.set_pvalues_and_annotate([pvalues_1to1[part][one]]) plt.tight_layout(pad=1.5) # plt.savefig(&quot;/Users/esmeralda/Documents/TFM/article/omegaratio.pdf&quot;, format= &quot;pdf&quot;) plt.show() 6.1.6 Test selection Finally, we determine whether the omega values significantly deviate from zero, indicating the presence or absence of selection. def test_one(df_values, mean): results_test = {&quot;Tips:&quot;: [scipy.stats.ttest_1samp(df_values[0][0], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[0][1], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[0][2], popmean=mean).pvalue], &quot;Branches:&quot;: [scipy.stats.ttest_1samp(df_values[1][0], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[1][1], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[1][2], popmean=mean).pvalue], &quot;Tree&quot;: [scipy.stats.ttest_1samp(df_values[2][0], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[2][1], popmean=mean).pvalue, scipy.stats.ttest_1samp(df_values[2][2], popmean=mean).pvalue]} df = pd.DataFrame.from_dict(results_test) df.index = [&quot;p22&quot;, &quot;p19&quot;, &quot;CP&quot;] return df 6.1.7 Run def main(): dfs = [] significance = 0.1 path_p22 = &#39;p22_nt_alignment.fasta.ABSREL.json&#39; path_p19 = &#39;p19_nt_alignment.fasta.ABSREL.json&#39; path_RdRp = &#39;RdRp_nt_alignment.fasta.ABSREL.json&#39; path_cp = &#39;cp_nt_alignment.fasta.ABSREL.json&#39; # Read json files of each gene paths = [path_p22, path_p19, path_RdRp, path_cp] for path in paths: df = read_branches(path) dfs.append(add_info(df, significance)) # Filling missing nodes with zero values missing_nodes_p22 = [&quot;Node11&quot;, &quot;Node18&quot;, &quot;Node6&quot;] missing_nodes_p19 = [&quot;Node11&quot;, &quot;Node18&quot;, &quot;Node3&quot;, &quot;Node6&quot;] df_p22 = fill_missing_nodes(dfs[0], missing_nodes_p22) df_p19 = fill_missing_nodes(dfs[1], missing_nodes_p19) df_RdRp = dfs[2] df_cp = dfs[3] # Generate relative values for all, tips and nodes genes = [df_p22, df_p19, df_cp] results = relativize(genes, df_RdRp) tips, nodes = divide_branches(results, df_RdRp) # Calculate pvalues in pairs pvalues_1to1 = [] df_values = [] sep_types = [tips, nodes, results] for chunk in sep_types: pvalues_1to1.append(calc_pvalues(chunk)) df_values.append(info_to_dataframe(chunk)) # Get formatted pvalues formatted_pvalues = format_pvalues(pvalues_1to1) # Boxplots with significance plot_diff_types(df_values, pvalues_1to1, formatted_pvalues) plot_one_type(df_values, pvalues_1to1, formatted_pvalues, 0) # T test one sample vs mean = 0 print(test_one(sep_types, 0)) 6.2 FEL for correlations In this section, we read JSON files containing the results of p19 and p22 analyses, generated with the FEL method of Hyphy (Kosakovsky Pond and Frost 2005). The objective is to establish correlations between selection and infer the extent to which the correlation is influenced by the secondary structure of the proteins they encode. ###Libraries and json files import json import matplotlib.pyplot as plt import numpy as np import pandas as pd import scipy.stats import seaborn as sns First, we need to read the JSON files containing the results of the FEL analysis for both genes. def read_json(path): with open(path) as user_file: file_contents = user_file.read() parsed_json = json.loads(file_contents) values = {&quot;codon&quot;: list(range(len(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;]))), &quot;alpha&quot;: [], &quot;beta&quot;: [], &quot;pvalue&quot;: []} for i in range(len(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;])): values[&#39;alpha&#39;].append(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;][i][0]) values[&#39;beta&#39;].append(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;][i][1]) values[&#39;pvalue&#39;].append(parsed_json[&#39;MLE&#39;][&#39;content&#39;][&quot;0&quot;][i][4]) return pd.DataFrame.from_dict(values) 6.2.1 Significance and difference Now, information about significance and the difference between the estimated rates of non-synonymous (beta) and synonymous (alpha) substitutions. def add_info(data, significance): data[&#39;beta - alpha&#39;] = data[&#39;beta&#39;] - data[&#39;alpha&#39;] data[&quot;signif&quot;] = np.where(data[&#39;pvalue&#39;] &lt; significance, True, False) return data We can even print the codon positions that are detected to be under significant selection. def significative_codons(data): return (list(data[(data[&quot;signif&quot;] == True) &amp; (data[&quot;beta - alpha&quot;] &gt; 0)].index + 1) +\\ list(data[(data[&quot;signif&quot;] == True) &amp; (data[&quot;beta - alpha&quot;] &lt; 0)].index + 1)) 6.2.2 Plot correlation As we know the frameshift of one gene, we can plot selection values, specifically the difference between beta and alpha, by positions in p19 and p22. Additionally, we can denote significance using colors. def plot_correlation(data1, data2, shift, colors): plt.style.use(&#39;default&#39;) fig = plt.figure(figsize=(6,12)) ax = fig.add_subplot(111) fontsize = 24 points_size = 20 plt.ylim(-14,11) plt.xlim(-16,7) plt.scatter(data2[&quot;beta - alpha&quot;][shift:len(data1[&quot;beta - alpha&quot;]) + shift], data1[&quot;beta - alpha&quot;], s=points_size, c=colors) plt.xlabel(&quot;$\\\\beta$ - $\\\\alpha$ (p22)&quot;) plt.ylabel(&quot;$\\\\beta$ - $\\\\alpha$ (p19)&quot;) plt.axhline(0,color=&#39;black&#39;, linewidth=1, ls=&quot;--&quot;, alpha=0.5) # x = 0 plt.axvline(0,color=&#39;black&#39;, linewidth=1, ls=&quot;--&quot;, alpha=0.5) # x = 0 ax.xaxis.label.set_fontsize(fontsize) ax.yaxis.label.set_fontsize(fontsize) plt.xticks(fontsize=fontsize - 1) plt.yticks(fontsize=fontsize - 1) plt.tight_layout(pad=1.5) plt.show() def define_colors(data1, data2): color_p19 = &quot;#FFD500&quot; color_p22 = &quot;#9867F4&quot; color_both = &quot;#242038&quot; others = &quot;#A2A2A2&quot; colors = [] for i in range(len(data1)): if data1[&quot;signif&quot;][i] and data2[&quot;signif&quot;][i]: colors.append(color_both) elif data2[&quot;signif&quot;][i]: colors.append(color_p22) elif data1[&quot;signif&quot;][i]: colors.append(color_p19) else: colors.append(others) return colors 6.2.3 Test correlation of selection After creating a combined dataframe based on the shift between both genes, we proceed to search for correlation, considering all values or only those that were deemed significant (of p19, p22, both, or at least one of them). During this analysis, we observed a potential linear dependence in the upper left quadrant. As a result, we calculated the Pearson correlation coefficient and its corresponding p-value. def combine_genes(data1, data2, shift): combi = pd.DataFrame() combi[&quot;p22 diff&quot;] = list(data2[&quot;beta - alpha&quot;][shift:len(data1[&quot;beta - alpha&quot;]) + shift]) combi[&quot;p19 diff&quot;] = list(data1[&quot;beta - alpha&quot;]) combi[&quot;p22_signif&quot;] = list(data2[&quot;signif&quot;][shift:len(data1[&quot;beta - alpha&quot;]) + shift]) combi[&quot;p19_signif&quot;] = list(data1[&quot;signif&quot;]) return combi def search_correlation(combi, num): if num == 0: # ALL corr = correl_total(combi) elif num == 1: # p19 corr = correl_one(combi, num) elif num == 2: # p22 corr = correl_one(combi, num) elif num == 3: # At least one corr = correl_least_one(combi) else: # Both significative corr = correl_both(combi) return (corr, scipy.stats.fisher_exact(corr)) def correl_total(combi): total = [[len(combi[(combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)]), len(combi[(combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)])], [len(combi[(combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)]), len(combi[(combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)])]] return total def correl_least_one(combi): one_atleast = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])]] return one_atleast def correl_both(combi): both_sig_table = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] &amp; combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;] | combi[&quot;p19_signif&quot;]))])]] return both_sig_table def correl_one(combi, num): if num == 1: sig_table = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p19_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p19_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p19_signif&quot;]))])]] else: sig_table = [[len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &gt; 0)) &amp; (combi[&quot;p22_signif&quot;]))])], [len(combi[(((combi[&quot;p22 diff&quot;] &gt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;]))]), len(combi[(((combi[&quot;p22 diff&quot;] &lt; 0) &amp; (combi[&quot;p19 diff&quot;] &lt; 0)) &amp; (combi[&quot;p22_signif&quot;]))])]] return sig_table def pearson_upper_left(combi): upper_left = combi[(combi[&quot;p19 diff&quot;] &gt; 0) &amp; (combi[&quot;p22 diff&quot;] &lt; 0)] y = upper_left[&quot;p19 diff&quot;] x = upper_left[&quot;p22 diff&quot;] return scipy.stats.pearsonr(x, y) 6.2.4 Correlation 2D Another point to be investigated is the possible correlation between the secondary structures of both proteins. def corr_struct(struct1, struct2, shift): combinations_3d = pd.DataFrame(0, columns=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;], index=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;]) for pos in range(len(struct1)): combinations_3d[struct2[pos+shift]][struct1[pos]] += 1 res = list(scipy.stats.chi2_contingency(combinations_3d)) res.append(combinations_3d) return res The resulting contingency table can be visually represented with colors, indicating the distribution of data. Additionally, this representation can be combined with the expected frequencies, allowing us to create a table displaying the ratio of observed to expected values. This ratio provides informative insights into the data distribution. def plot_dist_3D(combinations_3d, expected=0): if isinstance(expected, int): data = combinations_3d else: data = combinations_3d / pd.DataFrame(expected, columns=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;], index=[&quot;H&quot;, &quot;S&quot;, &quot;L&quot;]) plt.figure(figsize=(8, 6)) sns.heatmap(data, annot=True, cmap=&#39;YlGnBu&#39;) plt.xlabel(&#39;p22&#39;) plt.ylabel(&#39;p19&#39;) plt.show() 6.2.5 Selection in 2D This additional division aims to direct attention to the secondary structures separately. Using the following function, nine contingency tables (3x3) are calculated, considering neutral, positive, and negative selection in both frames. The distinction between these tables lies in the exclusive presence of codons that belong to regions forming helices, strands, or loops (or all). def selection_structure(p19_struct, p22_struct, df_p19, df_p22, comparison_letters, shift): macro_results = [] for letters in comparison_letters: result = pd.DataFrame(0, columns = [&quot;Neg.&quot;, &quot;Pos.&quot;, &quot;-&quot;], index = [&quot;Neg.&quot;, &quot;Pos.&quot;, &quot;-&quot;]) for i in range(len(p19_struct)): if p19_struct[i] == letters[0] and p22_struct[i+shift] == letters[1]: p19_value = df_p19[&quot;beta - alpha&quot;][i] p22_value = df_p22[&quot;beta - alpha&quot;][i+shift] if p19_value == 0 and p22_value == 0: result[&quot;-&quot;][&quot;-&quot;] += 1 elif p19_value == 0 and p22_value &gt; 0: result[&quot;Pos.&quot;][&quot;-&quot;] += 1 elif p19_value == 0 and p22_value &lt; 0: result[&quot;Neg.&quot;][&quot;-&quot;] += 1 elif p19_value &gt; 0 and p22_value == 0: result[&quot;-&quot;][&quot;Pos.&quot;] += 1 elif p19_value &lt; 0 and p22_value == 0: result[&quot;-&quot;][&quot;Neg.&quot;] += 1 elif p19_value &gt; 0 and p22_value &gt; 0: result[&quot;Pos.&quot;][&quot;Pos.&quot;] += 1 elif p19_value &lt; 0 and p22_value &lt; 0: result[&quot;Neg.&quot;][&quot;Neg.&quot;] += 1 elif p19_value &gt; 0 and p22_value &lt; 0: result[&quot;Neg.&quot;][&quot;Pos.&quot;] += 1 elif p19_value &lt; 0 and p22_value &gt; 0: result[&quot;Pos.&quot;][&quot;Neg.&quot;] += 1 macro_results.append(result) return macro_results 6.2.6 Run Notice that, for every position in p19 and p22, we indicate the corresponding secondary structure. H: helix, S:strand and L: loop. def main(): path_p19 = &#39;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/FEL_p19_local/p19_FEL.json&#39; path_p22 = &#39;/Users/esmeralda/Documents/TFM/RevTrans/final/nt/alignments/FEL_p22_local/firts.json&#39; # Read json files and add information significance = 0.1 df_p19 = add_info(read_json(path_p19), significance) df_p22 = add_info(read_json(path_p22), significance) # Print significative codons print(&quot;Signif. p19:&quot;, significative_codons(df_p19), &quot;Signif. p22:&quot;, significative_codons(df_p22)) # Plot dots +10 and +11 codons colors = define_colors(df_p19, df_p22) plot_correlation(df_p19, df_p22, 10, colors) plot_correlation(df_p19, df_p22, 11, colors) # Combine both sequences with a shift p19_p22 = combine_genes(df_p19, df_p22, 10) # Search correlations correlations = [&quot;All&quot;, &quot;Only p19 significant&quot;, &quot;Only p22 significant&quot;, &quot;At least one significant&quot;, &quot;Both significant&quot;] for option in range(5): len_hyphen = (50-len(correlations[option]))//2 print(&quot;-&quot;*len_hyphen, correlations[option], &quot;-&quot;*len_hyphen) res = search_correlation(p19_p22, option) print(&quot;Contingency table:\\n&quot;, res[0]) print(&quot;Statistic (Fisher&#39;s exact test):\\n&quot;, res[0][0]) print(&quot;p value (Fisher&#39;s exact test):\\n&quot;, res[0][1]) # Pearson correlation correlation_coef, p_value = pearson_upper_left(p19_p22) print(&quot;Pearson correlation coefficient:&quot;, correlation_coef) print(&quot;p-value:&quot;, p_value) # Info structure order = [&quot;H&quot;, &quot;S&quot;, &quot;L&quot;] p22_struct = [&quot;L&quot;]*16 + [&quot;S&quot;]*4 + [&quot;L&quot;]*4 + [&quot;S&quot;]*4 + [&quot;L&quot;]*6 + [&quot;S&quot;]*3 +\\ [&quot;L&quot;]*3 + [&quot;H&quot;]*10 + [&quot;L&quot;]*4 + [&quot;S&quot;]*13 + [&quot;L&quot;]*10 + [&quot;S&quot;]*5 +\\ [&quot;L&quot;]*9 + [&quot;S&quot;]*3 + [&quot;L&quot;]*9 + [&quot;S&quot;]*5 + [&quot;L&quot;]*15 + [&quot;S&quot;]*5 +\\ [&quot;L&quot;]*10 + [&quot;S&quot;]*14 + [&quot;L&quot;]*11 + [&quot;S&quot;]*4 + [&quot;H&quot;]*20 + [&quot;L&quot;]*2 p19_struct = [&quot;L&quot;]*5 + [&quot;H&quot;]*13 + [&quot;L&quot;]*19 + [&quot;H&quot;]*9 + [&quot;L&quot;]*11 + [&quot;S&quot;]*8 +\\ [&quot;L&quot;]*2 + [&quot;S&quot;]*8 + [&quot;L&quot;]*3 + [&quot;H&quot;]*10 + [&quot;L&quot;]*2 + [&quot;H&quot;]*11 +\\ [&quot;L&quot;]*7 + [&quot;S&quot;]*8 + [&quot;L&quot;]*2 + [&quot;S&quot;]*8 + [&quot;L&quot;]*2 + [&quot;H&quot;]*17 +\\ [&quot;L&quot;]*27 # (+10) Combinations 3D; Columns: p22 ; Rows: p19 ; PLOT chi2_stat, p_value, dof, expected, cont_table= \\ corr_struct(p19_struct, p22_struct, 10) expected = pd.DataFrame(expected, index=order, columns=order) print(&quot;+10\\nChi-Square Statistic:&quot;, chi2_stat) print(&quot;P-value:&quot;, p_value) print(&quot;Degrees of Freedom:&quot;, dof) print(&quot;Expected Frequencies:\\n&quot;, expected, &quot;\\nCounts:\\n&quot;, cont_table) plot_dist_3D(cont_table) plot_dist_3D(cont_table, expected) # (+11) Combinations 3D; Columns: p22 ; Rows: p19 ; PLOT chi2_stat, p_value, dof, expected, cont_table = \\ corr_struct(p19_struct, p22_struct, 11) expected = pd.DataFrame(expected, index=order, columns=order) print(&quot;+11\\nChi-Square Statistic:&quot;, chi2_stat) print(&quot;P-value:&quot;, p_value) print(&quot;Degrees of Freedom:&quot;, dof) print(&quot;Expected Frequencies:\\n&quot;, expected, &quot;\\nCounts:\\n&quot;, cont_table) plot_dist_3D(cont_table) plot_dist_3D(cont_table, expected) # Comparison selection structure comparison_letters = [(&quot;H&quot;, &quot;H&quot;), (&quot;H&quot;, &quot;S&quot;), (&quot;H&quot;, &quot;L&quot;), (&quot;S&quot;, &quot;S&quot;), (&quot;S&quot;, &quot;L&quot;), (&quot;S&quot;, &quot;H&quot;), (&quot;L&quot;, &quot;L&quot;), (&quot;L&quot;, &quot;S&quot;), (&quot;L&quot;, &quot;H&quot;)] list_tables = selection_structure(p19_struct, p22_struct, df_p19, df_p22, comparison_letters, 10) print(25*&quot;-&quot; + &quot;+10&quot; + 25*&quot;-&quot;) for pos, res in enumerate(comparison_letters): print(&quot;\\nComparison:&quot;, res) print(list_tables[pos]) list_tables = selection_structure(p19_struct, p22_struct, df_p19, df_p22, comparison_letters, 11) print(25*&quot;-&quot; + &quot;+11&quot; + 25*&quot;-&quot;) for pos, res in enumerate(comparison_letters): print(&quot;\\nComparison:&quot;, res) print(list_tables[pos]) if __name__ == &quot;__main__&quot;: main() References "]]
